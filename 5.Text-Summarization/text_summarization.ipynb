{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KoBART 를 이용한 텍스트 요약 시스템 구성\n",
    "#### author: judepark@jbnu.ac.kr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미 학습되어있는 모델을 불러와서 텍스트 요약 시스템을 돌려봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BartModel, PreTrainedTokenizerFast, BartForConditionalGeneration\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bafaa6394db44359d794d0a9cea652b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5b33e7f00145b7b2161e11e19d0d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9019fc3db1640d497089957194c70f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/666k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b14f7c1e5044c5090149934f03e85d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe193db323f24fcfad14c50e6d6b5b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문서: 과거를 떠올려보자. 방송을 보던 우리의 모습을. 독보적인 매체는 TV였다. 온 가족이 둘러앉아 TV를 봤다. 간혹 가족들끼리 뉴스와 드라마, 예능 프로그램을 둘러싸고 리모컨 쟁탈전이 벌어지기도  했다. 각자 선호하는 프로그램을 ‘본방’으로 보기 위한 싸움이었다. TV가 한 대인지 두 대인지 여부도 그래서 중요했다. 지금은 어떤가. ‘안방극장’이라는 말은 옛말이 됐다. TV가 없는 집도 많다. 미디어의 혜 택을 누릴 수 있는 방법은 늘어났다. 각자의 방에서 각자의 휴대폰으로, 노트북으로, 태블릿으로 콘텐츠 를 즐긴다.\n",
      "요약 결과: TV가 없는 집도 많아지고 미디어의 혜 택을 누릴 수 있는 방법은 늘어났다.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained('gogamza/kobart-summarization')\n",
    "model = BartForConditionalGeneration.from_pretrained('gogamza/kobart-summarization')\n",
    "\n",
    "text = \"과거를 떠올려보자. 방송을 보던 우리의 모습을. 독보적인 매체는 TV였다. 온 가족이 둘러앉아 TV를 봤다. 간혹 가족들끼리 뉴스와 드라마, 예능 프로그램을 둘러싸고 리모컨 쟁탈전이 벌어지기도  했다. 각자 선호하는 프로그램을 ‘본방’으로 보기 위한 싸움이었다. TV가 한 대인지 두 대인지 여부도 그래서 중요했다. 지금은 어떤가. ‘안방극장’이라는 말은 옛말이 됐다. TV가 없는 집도 많다. 미디어의 혜 택을 누릴 수 있는 방법은 늘어났다. 각자의 방에서 각자의 휴대폰으로, 노트북으로, 태블릿으로 콘텐츠 를 즐긴다.\"\n",
    "print(f'입력 문서: {text}')\n",
    "\n",
    "raw_input_ids = tokenizer.encode(text)\n",
    "input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "summary_ids = model.generate(torch.tensor([input_ids]))\n",
    "print(f'요약 결과: {tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 요약 시스템 학습 (Fine-tuning) 하기\n",
    "### 1. 데이터 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train.tsv', 'r', encoding='utf-8') as f:\n",
    "    train_dataset = [i.strip() for i in f][1:101]\n",
    "\n",
    "with open('./data/test.tsv', 'r', encoding='utf-8') as f:\n",
    "    test_dataset = [i.strip() for i in f][1:11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"일제 강제징용피해자들이 지난 2월 발의된 ‘근로정신대 피해자 지원법률안’의 조속한 통과를 촉구 했다. 시민단체 ‘근로정신대 할머니와 함께 하는 시민모임’은 13일 광주시의회 시민 소통실에서 기자회견을 열고 “피해자들을 더 이상 외면하지 말고 지원법을 제정해달라”고 주장했다. 시민모임은 “광복 74년이 됐지만, 여자근로정신대 피해자들은 아직도 일제가 씌운 굴레에서 벗어나지 못하고 있는 처지”라면서 일본정부와 한국정부 양쪽 모두의 잘못을 지적했다. 이들은 “해방 후 진실규명과 명예회복을 전혀 하지 않은 일본정부의 잘못이 가장 크다”고 비판했다. 이어 “우리나라의 많은 국민이 ‘근로정신대’와 일본군 ‘위안부’ 문제를 아예 구별하지 못하고 있는 것은 제대로 된 진상조사나 역사교육을 하지 않고 있는 우리 정부의 탓도 있다”고 덧붙였다. 이들은 또 “어렵게 용기를 내 근로정신대 피해자라고 고백을 하더라도 위안부 피해자와 달리 국가로부터 어떤 지원이나 위로도 받을 수 없었다”며 “이런 현실 앞에 한국 정부는 그 책임에서 자유로울 수 없다”고 설명했다. 시민모임은 “이미 지난 2월 바른미래당 김동철(광주 광산갑) 의원이 근로정신대 피해자 지원법률안을 발의했지만, 국회에선 담당 상임위원회에 상정조차 안되고 있다”면서 “근로정신대 피해자들을 위해 조속히 법률 제정에 나서야 한다”고 요구했다.\\t13일 광주시의회 시민 소통실에서 시민단체 '근로정신대 할머니와 함께 하는 시민모임'은 기자회견을 열어 지난 2월 발의된 '근로정신대 피해자 지원법률안'의 조속한 통과를 요구했다.\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터는 입력 문서/요약문으로 구성되어 있습니다. 여기서 \\t로 입력 문서/요약문을 구분합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PyTorch Dataset 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "\n",
    "class KoBARTSummaryDataset(Dataset):\n",
    "    def __init__(self, file, tok, max_len, pad_index = None, ignore_index=-100):\n",
    "        super().__init__()\n",
    "        self.tok = tok\n",
    "        self.max_len = max_len\n",
    "        self.docs = pd.read_csv(file, sep='\\t')\n",
    "        self.len = self.docs.shape[0]\n",
    "        if pad_index is None:\n",
    "            self.pad_index = self.tok.pad_token_id\n",
    "        else:\n",
    "            self.pad_index = pad_index\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def add_padding_data(self, inputs):\n",
    "        if len(inputs) < self.max_len:\n",
    "            pad = np.array([self.pad_index] *(self.max_len - len(inputs)))\n",
    "            inputs = np.concatenate([inputs, pad])\n",
    "        else:\n",
    "            inputs = inputs[:self.max_len]\n",
    "\n",
    "        return inputs\n",
    "\n",
    "    def add_ignored_data(self, inputs):\n",
    "        if len(inputs) < self.max_len:\n",
    "            pad = np.array([self.ignore_index] *(self.max_len - len(inputs)))\n",
    "            inputs = np.concatenate([inputs, pad])\n",
    "        else:\n",
    "            inputs = inputs[:self.max_len]\n",
    "\n",
    "        return inputs\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        instance = self.docs.iloc[idx]\n",
    "        input_ids = self.tok.encode(instance['news'])\n",
    "        input_ids = self.add_padding_data(input_ids)\n",
    "\n",
    "        label_ids = self.tok.encode(instance['summary'])\n",
    "        label_ids.append(self.tok.eos_token_id)\n",
    "        dec_input_ids = [self.pad_index]\n",
    "        dec_input_ids += label_ids[:-1]\n",
    "        dec_input_ids = self.add_padding_data(dec_input_ids)\n",
    "        label_ids = self.add_ignored_data(label_ids)\n",
    "\n",
    "        return {'input_ids': np.array(input_ids, dtype=np.int_),\n",
    "                'decoder_input_ids': np.array(dec_input_ids, dtype=np.int_),\n",
    "                'labels': np.array(label_ids, dtype=np.int_)}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5c56fc0ca5488fb5f89b93e15295d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0b624c929b48858e330c0f53f56335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/85.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aea1ff307194abb97258b65977bd27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/109 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd50ec2f431469cb875a3f9b8aea2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/666k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9017f71280f342dca28c9b3da605315b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba3d2fb7e6c466388ae68448c348026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/473M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"hyunwoongko/kobart\")\n",
    "model = BartForConditionalGeneration.from_pretrained(\"hyunwoongko/kobart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sum_dataset = KoBARTSummaryDataset('./data/train.tsv', tokenizer, max_len=128)\n",
    "test_sum_dataset = KoBARTSummaryDataset('./data/test.tsv', tokenizer, max_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_sum_dataset, batch_size=8, shuffle=True)\n",
    "test_dataloader = DataLoader(train_sum_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = model.parameters()\n",
    "optimizer = Adam(parameters, lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 2.5689656734466553: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 4281/4281 [08:17<00:00,  8.60it/s]\n"
     ]
    }
   ],
   "source": [
    "epoch = 1 # 1 epoch 만 학습합니다.\n",
    "is_cuda = True # GPU 환경입니다. \n",
    "\n",
    "if is_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "for e in range(epoch):\n",
    "    pbar = tqdm(train_dataloader, total=len(train_dataloader))\n",
    "    for batch in pbar:\n",
    "        optimizer.zero_grad()\n",
    "        batch = {k: v.cuda() for k, v in batch.items()} if is_cuda else batch\n",
    "        output = model(**batch)\n",
    "        loss = output.loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(f'epoch: {e} loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 문서: 과거를 떠올려보자. 방송을 보던 우리의 모습을. 독보적인 매체는 TV였다. 온 가족이 둘러앉아 TV를 봤다. 간혹 가족들끼리 뉴스와 드라마, 예능 프로그램을 둘러싸고 리모컨 쟁탈전이 벌어지기도  했다. 각자 선호하는 프로그램을 ‘본방’으로 보기 위한 싸움이었다. TV가 한 대인지 두 대인지 여부도 그래서 중요했다. 지금은 어떤가. ‘안방극장’이라는 말은 옛말이 됐다. TV가 없는 집도 많다. 미디어의 혜 택을 누릴 수 있는 방법은 늘어났다. 각자의 방에서 각자의 휴대폰으로, 노트북으로, 태블릿으로 콘텐츠 를 즐긴다.\n",
      "요약 결과: TV가 보는 재미와 함께 TV를 보는 재미도 함께 느낄 수 있다.\n"
     ]
    }
   ],
   "source": [
    "text = \"과거를 떠올려보자. 방송을 보던 우리의 모습을. 독보적인 매체는 TV였다. 온 가족이 둘러앉아 TV를 봤다. 간혹 가족들끼리 뉴스와 드라마, 예능 프로그램을 둘러싸고 리모컨 쟁탈전이 벌어지기도  했다. 각자 선호하는 프로그램을 ‘본방’으로 보기 위한 싸움이었다. TV가 한 대인지 두 대인지 여부도 그래서 중요했다. 지금은 어떤가. ‘안방극장’이라는 말은 옛말이 됐다. TV가 없는 집도 많다. 미디어의 혜 택을 누릴 수 있는 방법은 늘어났다. 각자의 방에서 각자의 휴대폰으로, 노트북으로, 태블릿으로 콘텐츠 를 즐긴다.\"\n",
    "print(f'입력 문서: {text}')\n",
    "\n",
    "raw_input_ids = tokenizer.encode(text)\n",
    "input_ids = [tokenizer.bos_token_id] + raw_input_ids + [tokenizer.eos_token_id]\n",
    "\n",
    "summary_ids = model.generate(torch.tensor([input_ids]).cuda())\n",
    "print(f'요약 결과: {tokenizer.decode(summary_ids.squeeze().tolist(), skip_special_tokens=True)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
